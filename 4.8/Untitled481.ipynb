{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "V0WHQ8hl8EkQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка PySpark в Google Colab\n",
        "!pip install pyspark\n",
        "\n",
        "# Импорт необходимых библиотек\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "import datetime as dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffgpEXgoCBUS",
        "outputId": "f5492635-0c23-442f-99eb-8d9a24f6f2df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Создаем сессию Spark\n",
        "spark = SparkSession.builder.appName(\"Forecast\").getOrCreate()\n",
        "\n",
        "# Создаем DataFrame для информации о среднедневном спросе\n",
        "demand_data = [(1, 1, 1, 100),\n",
        "               (1, 2, 2, 110),\n",
        "               (2, 1, 3, 120),\n",
        "               (2, 2, 3, 90),\n",
        "               (3, 1, 1, 70),\n",
        "               (3, 2, 2, 80)]\n",
        "\n",
        "demand_columns = [\"product\", \"location\", \"demand_id\", \"demand\"]\n",
        "demand_df = spark.createDataFrame(demand_data, demand_columns)\n",
        "\n",
        "# Создаем DataFrame для информации о складских запасах\n",
        "stock_data = [(1, 1, 1000),\n",
        "              (1, 2, 400),\n",
        "              (2, 2, 250)]\n",
        "\n",
        "stock_columns = [\"product\", \"location\", \"stock\"]\n",
        "stock_df = spark.createDataFrame(stock_data, stock_columns)\n",
        "\n",
        "# Создаем DataFrame с информацией о технических неделях\n",
        "technical_weeks = [(\"2023-08-01\", \"2023-08-06\"),\n",
        "                   (\"2023-08-07\", \"2023-08-13\"),\n",
        "                   (\"2023-08-14\", \"2023-08-20\"),\n",
        "                   (\"2023-08-21\", \"2023-08-27\"),\n",
        "                   (\"2023-08-28\", \"2023-08-31\")]\n",
        "\n",
        "weeks_columns = [\"start_date\", \"end_date\"]\n",
        "weeks_df = spark.createDataFrame(technical_weeks, weeks_columns)\n",
        "\n",
        "# Объединяем данные\n",
        "joined_data = demand_df.join(stock_df, [\"product\", \"location\"])\n",
        "\n",
        "# Присоединяем данные о технических неделях\n",
        "joined_data_with_weeks = joined_data.crossJoin(weeks_df)\n",
        "\n",
        "# Преобразуем даты в формат timestamp\n",
        "date_format = \"yyyy-MM-dd\"\n",
        "joined_data_with_weeks = joined_data_with_weeks \\\n",
        "    .withColumn(\"start_date\", F.to_date(F.col(\"start_date\"), date_format)) \\\n",
        "    .withColumn(\"end_date\", F.to_date(F.col(\"end_date\"), date_format))\n",
        "\n",
        "# Определяем окно по продукту, локации, технической неделе\n",
        "window_spec = Window.partitionBy(\"product\", \"location\", \"start_date\", \"end_date\").orderBy(\"start_date\")\n",
        "\n",
        "# Рассчитываем прогнозируемое количество проданных товаров и количество остатков на складе\n",
        "forecast_result = joined_data_with_weeks \\\n",
        "    .withColumn(\"forecast_demand\", F.sum(\"demand\").over(window_spec)) \\\n",
        "    .withColumn(\"forecast_stock\", F.last(\"stock\").over(window_spec))\n",
        "\n",
        "# Выводим результат\n",
        "forecast_result.select(\"product\", \"location\", \"start_date\", \"end_date\", \"forecast_demand\", \"forecast_stock\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ8g1TrNLm3h",
        "outputId": "ab52b5f6-bd22-460a-aa7e-c34a3e960019"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+----------+----------+---------------+--------------+\n",
            "|product|location|start_date|  end_date|forecast_demand|forecast_stock|\n",
            "+-------+--------+----------+----------+---------------+--------------+\n",
            "|      1|       1|2023-08-01|2023-08-06|            100|          1000|\n",
            "|      1|       1|2023-08-07|2023-08-13|            100|          1000|\n",
            "|      1|       1|2023-08-14|2023-08-20|            100|          1000|\n",
            "|      1|       1|2023-08-21|2023-08-27|            100|          1000|\n",
            "|      1|       1|2023-08-28|2023-08-31|            100|          1000|\n",
            "|      1|       2|2023-08-01|2023-08-06|            110|           400|\n",
            "|      1|       2|2023-08-07|2023-08-13|            110|           400|\n",
            "|      1|       2|2023-08-14|2023-08-20|            110|           400|\n",
            "|      1|       2|2023-08-21|2023-08-27|            110|           400|\n",
            "|      1|       2|2023-08-28|2023-08-31|            110|           400|\n",
            "|      2|       2|2023-08-01|2023-08-06|             90|           250|\n",
            "|      2|       2|2023-08-07|2023-08-13|             90|           250|\n",
            "|      2|       2|2023-08-14|2023-08-20|             90|           250|\n",
            "|      2|       2|2023-08-21|2023-08-27|             90|           250|\n",
            "|      2|       2|2023-08-28|2023-08-31|             90|           250|\n",
            "+-------+--------+----------+----------+---------------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}